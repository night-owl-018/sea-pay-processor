import os
from datetime import datetime

from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter

from app.core.logger import log
from app.core.config import (
    SUMMARY_TXT_FOLDER,
    SUMMARY_PDF_FOLDER,
    PACKAGE_FOLDER,
)


def _fmt_date(dt):
    if not dt or not hasattr(dt, "strftime"):
        return "UNKNOWN"
    return dt.strftime("%m-%d-%Y")


def _build_psd_summary_text(sd):
    rate = sd.get("rate", "").strip()
    first = sd.get("first", "").strip()
    last = sd.get("last", "").strip()
    name = f"{first} {last}".strip()

    # Reporting window (use earliest start, latest end across all sheets)
    rp = sd.get("reporting_periods", []) or []
    valid_starts = [r["start"] for r in rp if r.get("start")]
    valid_ends = [r["end"] for r in rp if r.get("end")]

    header_from = _fmt_date(min(valid_starts)) if valid_starts else "UNKNOWN"
    header_to = _fmt_date(max(valid_ends)) if valid_ends else "UNKNOWN"

    # Valid periods (Sea Pay authorized)
    periods = sorted(
        sd.get("periods", []),
        key=lambda p: p.get("start") or datetime.min,
    )

    # Invalid / non-payable entries
    invalid_rows = []

    for e in sd.get("skipped_unknown", []):
        date = e.get("date", "UNKNOWN")
        raw = (e.get("raw") or "").strip()
        up = raw.upper()
        if "SBTT" in up:
            reason = "SBTT / Training Event"
        elif "MITE" in up or "ATG" in up:
            reason = "Not Sea Pay Qualified"
        else:
            reason = "Unknown / Not Sea Pay Qualified"
        invalid_rows.append({
            "date": date,
            "raw": raw or "UNKNOWN",
            "reason": reason,
        })

    for e in sd.get("skipped_dupe", []):
        date = e.get("date", "UNKNOWN")
        ship = e.get("ship") or "UNKNOWN SHIP"
        reason = "Duplicate entry for date"
        invalid_rows.append({
            "date": date,
            "raw": ship,
            "reason": reason,
        })

    # Count of PG13s = count of valid periods
    pg13_count = len(periods)

    lines = []
    lines.append("PSD SEA PAY SUMMARY")
    lines.append("")
    member_line = f"{rate} {name}".strip() if rate else name
    lines.append(f"Member: {member_line}")
    lines.append(f"Documented Period: {header_from} to {header_to}")
    lines.append("")
    lines.append("VALID SEA PAY PERIODS (PAY AUTHORIZED):")
    if periods:
        for p in periods:
            ship = (p.get("ship") or "UNKNOWN").upper()
            s = _fmt_date(p.get("start"))
            e = _fmt_date(p.get("end"))
            lines.append(f"- {ship} | {s} TO {e}")
    else:
        lines.append("- None")
    lines.append("")
    lines.append("INVALID / NON-PAYABLE ENTRIES:")
    if invalid_rows:
        for r in invalid_rows:
            lines.append(f"- {r['raw']} | {r['date']} | {r['reason']}")
    else:
        lines.append("- None")
    lines.append("")
    lines.append("DOCUMENTS PROVIDED:")
    lines.append(f"- Generated Sea Pay PG13 ({pg13_count})")
    lines.append("- TORIS Sea Pay Cert Sheet")
    lines.append("- Summary PDF")
    lines.append("")
    lines.append("NOTES FOR PSD:")
    lines.append("- Valid events confirmed using continuous-date logic.")
    lines.append("- Non-platform, SBTT, and invalid rows removed per policy.")
    lines.append("- TORIS sheet corrected and annotated.")
    lines.append("")
    lines.append("Generated by STG1 NIVERA â€“ ATGSD SEA PAY PROCESSOR")

    return "\n".join(lines)


def _write_member_pdf(text, out_path):
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    c = canvas.Canvas(out_path, pagesize=letter)
    width, height = letter
    x = 40
    y = height - 40
    for line in text.split("\n"):
        if y < 60:
            c.showPage()
            y = height - 40
        c.setFont("Helvetica", 10)
        c.drawString(x, y, line)
        y -= 14
    c.save()


def write_summary_files(summary_data):
    """
    Build per-member PSD-optimized summaries (TXT + PDF)
    and a master TXT/PDF summary.
    """
    os.makedirs(SUMMARY_TXT_FOLDER, exist_ok=True)
    os.makedirs(SUMMARY_PDF_FOLDER, exist_ok=True)
    os.makedirs(PACKAGE_FOLDER, exist_ok=True)

    master_lines = []
    members = sorted(summary_data.keys())

    for key in members:
        sd = summary_data[key]
        text = _build_psd_summary_text(sd)

        rate = (sd.get("rate") or "").strip()
        last = (sd.get("last") or "").strip()
        first = (sd.get("first") or "").strip()

        base = f"{rate}_{last}_{first}".strip("_").replace(" ", "_")
        if not base:
            base = key.replace(" ", "_").replace(",", "_")

        txt_name = f"{base}__SUMMARY.txt"
        pdf_name = f"{base}__SUMMARY.pdf"

        txt_path = os.path.join(SUMMARY_TXT_FOLDER, txt_name)
        pdf_path = os.path.join(SUMMARY_PDF_FOLDER, pdf_name)

        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(text)

        _write_member_pdf(text, pdf_path)

        master_lines.append(text)
        master_lines.append("")  # blank line between members

    # Master TXT + PDF live in /output/PACKAGE/
    if master_lines:
        master_text = "\n".join(master_lines)
    else:
        master_text = "NO DATA"

    master_txt_path = os.path.join(PACKAGE_FOLDER, "MASTER_SUMMARY.txt")
    master_pdf_path = os.path.join(PACKAGE_FOLDER, "MASTER_SUMMARY.pdf")

    with open(master_txt_path, "w", encoding="utf-8") as f:
        f.write(master_text)

    _write_member_pdf(master_text, master_pdf_path)

    log("SUMMARY FILES (TXT/PDF) UPDATED")
